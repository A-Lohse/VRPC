{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d0c329",
   "metadata": {},
   "source": [
    "# This script takes the rawdataset.csv, users.txt, face_vars.csv and usernames.csv and cleans it in a myriad of ways. It outputs a cleandata.csv where it is all combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplt\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-qualification",
   "metadata": {},
   "source": [
    "importing a list of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statutory-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\\\users.txt\",'r') as file:\n",
    "    users = file.read().splitlines() \n",
    "    #users = [post[:-1] for post in users]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-harbor",
   "metadata": {},
   "source": [
    "reading in all the csv files from the subfolders, and appending them to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "double-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=['post_nr', 'date', 'text', 'likes', 'user', 'piclink', 'postlink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adverse-korean",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    path =  \"posts\\\\\"+ user +\"\\\\\" \n",
    "    csv_path = path + user +\".csv\"\n",
    "    pic_path = path + user + \"_piclinks.txt\"\n",
    "    post_path = path + user + \"_postlinks.txt\"\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(csv_path, usecols = [1,2,3,4])\n",
    "    \n",
    "    #concat the username\n",
    "    df['user'] = user\n",
    "    \n",
    "    with open(pic_path, 'r') as file:\n",
    "        pic_links = file.read().splitlines()\n",
    "    with open(post_path, 'r') as file:\n",
    "        post_links = file.read().splitlines()\n",
    "    \n",
    "    df['piclink'] = pic_links\n",
    "    df['postlink'] = post_links\n",
    "    #append the dataset\n",
    "    dataset = dataset.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-candidate",
   "metadata": {},
   "source": [
    "Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confidential-confidentiality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "third-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"rawdataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accessible-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"rawdataset.csv\", usecols=[2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "colored-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_nr</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "      <td>Nunarput ♥️</td>\n",
       "      <td>71 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4 DAYS AGO</td>\n",
       "      <td>So proud of @kunofencker. 🏆🏆🏆 You won the nati...</td>\n",
       "      <td>71 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FEBRUARY 2</td>\n",
       "      <td>Many people ask me how I can work as a parliam...</td>\n",
       "      <td>100 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JANUARY 23</td>\n",
       "      <td>Relatable af</td>\n",
       "      <td>108 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DECEMBER 22, 2020</td>\n",
       "      <td>So excited for the kids to get home to us. I e...</td>\n",
       "      <td>19 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>19</td>\n",
       "      <td>MARCH 19, 2019</td>\n",
       "      <td>På vej til Ilulissat ❤️ Glæder mig. Håber på g...</td>\n",
       "      <td>24 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11680</th>\n",
       "      <td>20</td>\n",
       "      <td>FEBRUARY 23, 2019</td>\n",
       "      <td>Så er vi klar til at heppe på @nina_k_j og Jul...</td>\n",
       "      <td>47 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>21</td>\n",
       "      <td>FEBRUARY 14, 2019</td>\n",
       "      <td>Disse dage besøger jeg Tasiilaq. Det er så smu...</td>\n",
       "      <td>41 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11682</th>\n",
       "      <td>22</td>\n",
       "      <td>DECEMBER 11, 2018</td>\n",
       "      <td>Veloverstået samtale salon med @emileperonard ...</td>\n",
       "      <td>45 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>23</td>\n",
       "      <td>DECEMBER 9, 2018</td>\n",
       "      <td>Sapaassuit aappaanni pilluaritsi 🎅🏽😊🇬🇱 Glædeli...</td>\n",
       "      <td>36 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11684 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_nr               date  \\\n",
       "0            0         3 DAYS AGO   \n",
       "1            1         4 DAYS AGO   \n",
       "2            2         FEBRUARY 2   \n",
       "3            3         JANUARY 23   \n",
       "4            4  DECEMBER 22, 2020   \n",
       "...        ...                ...   \n",
       "11679       19     MARCH 19, 2019   \n",
       "11680       20  FEBRUARY 23, 2019   \n",
       "11681       21  FEBRUARY 14, 2019   \n",
       "11682       22  DECEMBER 11, 2018   \n",
       "11683       23   DECEMBER 9, 2018   \n",
       "\n",
       "                                                    text      likes  \\\n",
       "0                                            Nunarput ♥️   71 likes   \n",
       "1      So proud of @kunofencker. 🏆🏆🏆 You won the nati...   71 likes   \n",
       "2      Many people ask me how I can work as a parliam...  100 likes   \n",
       "3                                           Relatable af  108 likes   \n",
       "4      So excited for the kids to get home to us. I e...   19 likes   \n",
       "...                                                  ...        ...   \n",
       "11679  På vej til Ilulissat ❤️ Glæder mig. Håber på g...   24 likes   \n",
       "11680  Så er vi klar til at heppe på @nina_k_j og Jul...   47 likes   \n",
       "11681  Disse dage besøger jeg Tasiilaq. Det er så smu...   41 likes   \n",
       "11682  Veloverstået samtale salon med @emileperonard ...   45 likes   \n",
       "11683  Sapaassuit aappaanni pilluaritsi 🎅🏽😊🇬🇱 Glædeli...   36 likes   \n",
       "\n",
       "                user  \n",
       "0            akimati  \n",
       "1            akimati  \n",
       "2            akimati  \n",
       "3            akimati  \n",
       "4            akimati  \n",
       "...              ...  \n",
       "11679  aaja_chemnitz  \n",
       "11680  aaja_chemnitz  \n",
       "11681  aaja_chemnitz  \n",
       "11682  aaja_chemnitz  \n",
       "11683  aaja_chemnitz  \n",
       "\n",
       "[11684 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-groove",
   "metadata": {},
   "source": [
    "Clean up some of the data. I begin by making likes into an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impaired-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_col = dataset['likes']\n",
    "likes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eligible-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in like_col:\n",
    "    if str(txt) != \"nan\":\n",
    "        num = str(txt).split()[0]\n",
    "        num = num.replace(\",\",\"\")\n",
    "        num = num.replace(\".\",\"\")\n",
    "        likes.append(int(num))\n",
    "    else:\n",
    "        likes.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "better-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['likes'] = likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "every-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_nr</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "      <td>Nunarput ♥️</td>\n",
       "      <td>71.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4 DAYS AGO</td>\n",
       "      <td>So proud of @kunofencker. 🏆🏆🏆 You won the nati...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FEBRUARY 2</td>\n",
       "      <td>Many people ask me how I can work as a parliam...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JANUARY 23</td>\n",
       "      <td>Relatable af</td>\n",
       "      <td>108.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DECEMBER 22, 2020</td>\n",
       "      <td>So excited for the kids to get home to us. I e...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>19</td>\n",
       "      <td>MARCH 19, 2019</td>\n",
       "      <td>På vej til Ilulissat ❤️ Glæder mig. Håber på g...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11680</th>\n",
       "      <td>20</td>\n",
       "      <td>FEBRUARY 23, 2019</td>\n",
       "      <td>Så er vi klar til at heppe på @nina_k_j og Jul...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>21</td>\n",
       "      <td>FEBRUARY 14, 2019</td>\n",
       "      <td>Disse dage besøger jeg Tasiilaq. Det er så smu...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11682</th>\n",
       "      <td>22</td>\n",
       "      <td>DECEMBER 11, 2018</td>\n",
       "      <td>Veloverstået samtale salon med @emileperonard ...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>23</td>\n",
       "      <td>DECEMBER 9, 2018</td>\n",
       "      <td>Sapaassuit aappaanni pilluaritsi 🎅🏽😊🇬🇱 Glædeli...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11684 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_nr               date  \\\n",
       "0            0         3 DAYS AGO   \n",
       "1            1         4 DAYS AGO   \n",
       "2            2         FEBRUARY 2   \n",
       "3            3         JANUARY 23   \n",
       "4            4  DECEMBER 22, 2020   \n",
       "...        ...                ...   \n",
       "11679       19     MARCH 19, 2019   \n",
       "11680       20  FEBRUARY 23, 2019   \n",
       "11681       21  FEBRUARY 14, 2019   \n",
       "11682       22  DECEMBER 11, 2018   \n",
       "11683       23   DECEMBER 9, 2018   \n",
       "\n",
       "                                                    text  likes           user  \n",
       "0                                            Nunarput ♥️   71.0        akimati  \n",
       "1      So proud of @kunofencker. 🏆🏆🏆 You won the nati...   71.0        akimati  \n",
       "2      Many people ask me how I can work as a parliam...  100.0        akimati  \n",
       "3                                           Relatable af  108.0        akimati  \n",
       "4      So excited for the kids to get home to us. I e...   19.0        akimati  \n",
       "...                                                  ...    ...            ...  \n",
       "11679  På vej til Ilulissat ❤️ Glæder mig. Håber på g...   24.0  aaja_chemnitz  \n",
       "11680  Så er vi klar til at heppe på @nina_k_j og Jul...   47.0  aaja_chemnitz  \n",
       "11681  Disse dage besøger jeg Tasiilaq. Det er så smu...   41.0  aaja_chemnitz  \n",
       "11682  Veloverstået samtale salon med @emileperonard ...   45.0  aaja_chemnitz  \n",
       "11683  Sapaassuit aappaanni pilluaritsi 🎅🏽😊🇬🇱 Glædeli...   36.0  aaja_chemnitz  \n",
       "\n",
       "[11684 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-saturday",
   "metadata": {},
   "source": [
    "I then change the date\n",
    "- at the very first i change the once with \"4 days ago \" etc into they apporpriate dates\n",
    "- then i split the standard date formatsinto day, month year - 3 different cols \n",
    "- i then make a combined date col\n",
    "- i then make this col into a datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aware-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = dataset['date']\n",
    "dates = []\n",
    "day = []\n",
    "month = []\n",
    "year = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(i):\n",
    "    if i == \"JANUARY\" or i == \"JANUAR\":\n",
    "        return 1\n",
    "    elif i == \"FEBRUARY\" or i == \"FEBRUAR\":\n",
    "        return 2\n",
    "    elif i == \"MARCH\" or i == \"MARTS\":\n",
    "        return 3\n",
    "    elif i == \"APRIL\":\n",
    "        return 4\n",
    "    elif i == \"MAY\"or i == \"MAJ\":\n",
    "        return 5\n",
    "    elif i == \"JUNE\"or i == \"JUNI\":\n",
    "        return 6\n",
    "    elif i == \"JULY\"or i == \"JULI\":\n",
    "        return 7\n",
    "    elif i == \"AUGUST\":\n",
    "        return 8\n",
    "    elif i == \"SEPTEMBER\":\n",
    "        return 9\n",
    "    elif i == \"OCTOBER\"or i == \"OKTOBER\":\n",
    "        return 10\n",
    "    elif i == \"NOVEMBER\":\n",
    "        return 11\n",
    "    elif i == \"DECEMBER\":\n",
    "        return 12\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "casual-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_month = [\"JANUARY\",\n",
    "                 \"JANUAR\",\n",
    "                 \"FEBRUARY\",\n",
    "                 \"FEBRUAR\",\n",
    "                 \"MARCH\",\n",
    "                 \"MARTS\",\n",
    "                 \"APRIL\",\n",
    "                 \"MAY\",\n",
    "                 \"MAJ\",\n",
    "                 \"JUNE\",\n",
    "                 \"JUNI\",\n",
    "                 \"JULY\",\n",
    "                 \"JULI\",\n",
    "                 \"AUGUST\",\n",
    "                 \"SEPTEMBER\",\n",
    "                 \"OCTOBER\",\n",
    "                 \"OKTOBER\",\n",
    "                 \"NOVEMBER\",\n",
    "                 \"DECEMBER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "binding-village",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dt in date_col:\n",
    "    #if it is not nan\n",
    "    if str(dt) != \"nan\":\n",
    "        #this works for all the normal dates, also the ones with out year. but not for the \"x days ago\"\n",
    "        split_date = dt.split(maxsplit = 3)\n",
    "        #print(split_date)\n",
    "        \n",
    "        #if the month is first (format -m-d-y)\n",
    "        if split_date[0] in list_of_month:\n",
    "            month.append(mapping(split_date[0]))\n",
    "            day.append(split_date[1].replace(\",\",\"\"))\n",
    "            try:\n",
    "                year.append(split_date[2])\n",
    "            except:\n",
    "                #if there is no year, it means that it is the current year\n",
    "                year.append(2021)\n",
    "            #append in y-m-d format\n",
    "            dates.append(str(year[-1]) + \"-\" + str(month[-1]) + \"-\" + str(day[-1]))\n",
    "        #If the format is d-m-y\n",
    "        elif split_date[1] in list_of_month:\n",
    "            month.append(mapping(split_date[1]))\n",
    "            day.append(split_date[0].replace(\".\",\"\"))\n",
    "            try:\n",
    "                year.append(split_date[2])\n",
    "            except:\n",
    "                #if there is no year, it means that it is the current year\n",
    "                year.append(2021)\n",
    "                \n",
    "            #append in y-m-d format\n",
    "            dates.append(str(year[-1]) + \"-\" + str(month[-1]) + \"-\" + str(day[-1]))\n",
    "        else:\n",
    "            #there are 2 formats Danish and English for \"3 days ago\" or \"For 3 dage siden\"\n",
    "            #they are all subtracted from the 18-02-2021. This is not entirely correct \n",
    "            # as some post were scraped on the 15th, 16th and 17th. However the notes on which are lost on a broken harddisk\n",
    "            # it does not matter for the results. as i examine the periode clode to 26th Feb 2020. \n",
    "            if dt.split()[0].isdigit():\n",
    "                day.append(18 - int(dt.split()[0]))\n",
    "            elif dt.split()[1].isdigit():\n",
    "                day.append(18 - int(dt.split()[1]))\n",
    "            #all in February 2021\n",
    "            month.append(2)\n",
    "            year.append(2021)\n",
    "            \n",
    "            dates.append(str(year[-1]) + \"-\" + str(month[-1]) + \"-\" + str(day[-1]))\n",
    "\n",
    "\n",
    "    else:\n",
    "        day.append(np.nan)\n",
    "        month.append(np.nan)\n",
    "        year.append(np.nan)\n",
    "        dates.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "breeding-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date_clean'] = dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-upgrade",
   "metadata": {},
   "source": [
    "I then make the date into a datetime object and calculate the days till the 26th of August 2020, the date of the speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handmade-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "linde_date = datetime.strptime(\"2020-08-26\", \"%Y-%m-%d\")\n",
    "linde_date_06 = datetime.strptime(\"2020-09-06\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subtle-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = []\n",
    "datedif = []\n",
    "datedif_06 = []\n",
    "for dt in dataset['date_clean']:\n",
    "    try:\n",
    "        datetimes.append(datetime.strptime(dt, \"%Y-%m-%d\"))\n",
    "        datedif.append((datetimes[-1] - linde_date).days)\n",
    "        datedif_06.append((datetimes[-1] - linde_date_06).days)\n",
    "\n",
    "    except: \n",
    "        try:\n",
    "            datetimes.append(datetime.strptime(dt, \"%Y-%m-%d\"))\n",
    "            datedif.append((datetimes[-1] - linde_date).days)\n",
    "            datedif_06.append((datetimes[-1] - linde_date_06).days)\n",
    "\n",
    "        except:\n",
    "            datetimes.append(np.nan)\n",
    "            datedif.append(np.nan)\n",
    "            datedif_06.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "weird-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['datetime'] = datetimes\n",
    "dataset['days_till_linde'] = datedif\n",
    "dataset['days_till_linde_06'] = datedif_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "million-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"C:\\\\Users\\\\August\\\\OneDrive - Københavns Universitet\\\\Documents\\\\Uni\\\\Kandidat i Statskundskab\\\\Speciale\\\\kode\")\n",
    "#dataset = pd.read_csv(\"cleandata.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mediterranean-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C:\\\\Users\\\\August\\\\OneDrive - Københavns Universitet\\\\Documents\\\\Uni\\\\Kandidat i Statskundskab\\\\Speciale\\\\kode\\\\posts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outstanding-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset[\"path\"] = [path + \"\\\\\" + str(dataset['user'][i]) + \"\\\\pic_\" + str(dataset['post_nr'][i]) + \".jpeg\" for i in range(len(dataset))]\n",
    "dataset[\"path\"] = [\"posts\\\\\" + str(dataset['user'][i]) + \"\\\\pic_\" + str(dataset['post_nr'][i]) + \".jpeg\" for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-quarterly",
   "metadata": {},
   "source": [
    "## read in the gender amount of people data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thirty-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dataset = pd.read_csv(\"data\\\\face_vars.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broke-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['n_people'] = gender_dataset['n_people']\n",
    "dataset['n_women'] = gender_dataset['n_women']\n",
    "dataset['n_men'] = gender_dataset['n_men']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d843a",
   "metadata": {},
   "source": [
    "Remove imagewith more than 4 people (5 or more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5799d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove observations from before the alloted time)\n",
    "dateend = datetime(2021,2,4)\n",
    "dstart = datetime(2020,2,26)\n",
    "linde_date = datetime.strptime(\"2020-08-26\", \"%Y-%m-%d\")\n",
    "dataset = dataset[dataset['datetime'] > dstart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11810b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnv664\\AppData\\Local\\Temp/ipykernel_14592/2280790094.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['date_clean'] = [datetime.strptime(str(d), \"%Y-%m-%d\") for d in dataset['date_clean']]\n"
     ]
    }
   ],
   "source": [
    "dataset['date_clean'] = [datetime.strptime(str(d), \"%Y-%m-%d\") for d in dataset['date_clean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d10f4471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10416"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d13b1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "47.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(dataset['n_people'] > 4))\n",
    "print(dataset['n_people'].max())\n",
    "dataset = dataset[dataset['n_people'] < 5]\n",
    "dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93977d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10192"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c76d9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-peripheral",
   "metadata": {},
   "source": [
    "I make a share of women var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "exclusive-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    \n",
    "    try:\n",
    "        dataset.loc[i,'share_women'] = int(dataset.loc[i,'n_women']) / int(dataset.loc[i,'n_people'])\n",
    "        dataset.loc[i,'share_women_no_none'] = int(dataset.loc[i,'n_women']) / int(dataset.loc[i,'n_people'])\n",
    "    except ZeroDivisionError:\n",
    "        dataset.loc[i,'share_women'] = 0\n",
    "        dataset.loc[i,'share_women_no_none'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-memorabilia",
   "metadata": {},
   "source": [
    "I then define if it is before or after linde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "golden-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "before =dataset['datetime'] < linde_date\n",
    "after = dataset['datetime'] >= linde_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "important-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#published on the 11th of september\n",
    "before_06 =dataset['datetime'] < linde_date + timedelta(11)\n",
    "after_06 = dataset['datetime'] >= linde_date + timedelta(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nervous-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[before,'treatment'] = 0\n",
    "dataset.loc[after,'treatment'] = 1\n",
    "dataset.loc[before_06,'treatment_06'] = 0\n",
    "dataset.loc[after_06,'treatment_06'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-contrary",
   "metadata": {},
   "source": [
    "I proceed to remove the observations without a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "treated-transsexual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                   0\n",
       "index                     0\n",
       "post_nr                   0\n",
       "date                      0\n",
       "text                    164\n",
       "likes                   966\n",
       "user                      0\n",
       "date_clean                0\n",
       "datetime                  0\n",
       "days_till_linde           0\n",
       "days_till_linde_06        0\n",
       "path                      0\n",
       "n_people                  0\n",
       "n_women                   0\n",
       "n_men                     0\n",
       "share_women               0\n",
       "share_women_no_none    3941\n",
       "treatment                 0\n",
       "treatment_06              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "raised-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['date'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "balanced-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                   0\n",
       "index                     0\n",
       "post_nr                   0\n",
       "date                      0\n",
       "text                    164\n",
       "likes                   966\n",
       "user                      0\n",
       "date_clean                0\n",
       "datetime                  0\n",
       "days_till_linde           0\n",
       "days_till_linde_06        0\n",
       "path                      0\n",
       "n_people                  0\n",
       "n_women                   0\n",
       "n_men                     0\n",
       "share_women               0\n",
       "share_women_no_none    3941\n",
       "treatment                 0\n",
       "treatment_06              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "joint-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10192"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "theoretical-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(\"data\\\\usernames.csv\", sep=\";\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "healthy-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>navn</th>\n",
       "      <th>køn</th>\n",
       "      <th>parti</th>\n",
       "      <th>blok</th>\n",
       "      <th>dato for indsamling</th>\n",
       "      <th>valgperiode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akimati</td>\n",
       "      <td>Aki-Matilda Høegh-Dam</td>\n",
       "      <td>f</td>\n",
       "      <td>Siumut</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexvanopslagh</td>\n",
       "      <td>Alex Vanopslagh</td>\n",
       "      <td>m</td>\n",
       "      <td>Liberal Alliance</td>\n",
       "      <td>b</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andreas.steenberg</td>\n",
       "      <td>Andreas Steenberg</td>\n",
       "      <td>m</td>\n",
       "      <td>Radikale venstre</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anehalsboe</td>\n",
       "      <td>Ane Halsboe-Jørgensen</td>\n",
       "      <td>f</td>\n",
       "      <td>Socialdemokratiet</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annehonoreoestergaard</td>\n",
       "      <td>Anne Honoré Østergaard</td>\n",
       "      <td>f</td>\n",
       "      <td>Venstre</td>\n",
       "      <td>b</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>troelsravn1</td>\n",
       "      <td>Troels Ravn</td>\n",
       "      <td>m</td>\n",
       "      <td>Socialdemokratiet</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ullatornaes</td>\n",
       "      <td>Ulla Tørnæs</td>\n",
       "      <td>f</td>\n",
       "      <td>Venstre</td>\n",
       "      <td>b</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>victoria.r.velasquez</td>\n",
       "      <td>Victoria Vela?squez</td>\n",
       "      <td>f</td>\n",
       "      <td>Enhedslisten</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>zenia.stampe</td>\n",
       "      <td>Zenia Stampe</td>\n",
       "      <td>f</td>\n",
       "      <td>Radikale venstre</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>aaja_chemnitz</td>\n",
       "      <td>aaja chemnitz larsen</td>\n",
       "      <td>f</td>\n",
       "      <td>Inuit Ataqatigiit</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user                    navn køn               parti  \\\n",
       "0                  akimati   Aki-Matilda Høegh-Dam    f             Siumut   \n",
       "1           alexvanopslagh         Alex Vanopslagh    m   Liberal Alliance   \n",
       "2        andreas.steenberg       Andreas Steenberg    m   Radikale venstre   \n",
       "3               anehalsboe   Ane Halsboe-Jørgensen    f  Socialdemokratiet   \n",
       "4    annehonoreoestergaard  Anne Honoré Østergaard    f            Venstre   \n",
       "..                     ...                     ...  ...                ...   \n",
       "131            troelsravn1             Troels Ravn    m  Socialdemokratiet   \n",
       "132            ullatornaes             Ulla Tørnæs    f            Venstre   \n",
       "133   victoria.r.velasquez     Victoria Vela?squez    f       Enhedslisten   \n",
       "134           zenia.stampe            Zenia Stampe    f   Radikale venstre   \n",
       "135          aaja_chemnitz    aaja chemnitz larsen    f  Inuit Ataqatigiit   \n",
       "\n",
       "    blok dato for indsamling  valgperiode  \n",
       "0      r          11-03-2021         2019  \n",
       "1      b          11-03-2021         2019  \n",
       "2      r          11-03-2021         2019  \n",
       "3      r          11-03-2021         2019  \n",
       "4      b          11-03-2021         2019  \n",
       "..   ...                 ...          ...  \n",
       "131    r          11-03-2021         2019  \n",
       "132    b          11-03-2021         2019  \n",
       "133    r          11-03-2021         2019  \n",
       "134    r          11-03-2021         2019  \n",
       "135    r          11-03-2021         2019  \n",
       "\n",
       "[136 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "accomplished-catalyst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(user_data)):\n",
    "    name = user_data.loc[i,'user']\n",
    "    \n",
    "    dataset.loc[dataset['user']==name,'name'] =  user_data.loc[i,'navn']\n",
    "    dataset.loc[dataset['user']==name,'sex'] =  user_data.loc[i,'køn ']\n",
    "    dataset.loc[dataset['user']==name, 'party'] =  user_data.loc[i,'parti']\n",
    "    dataset.loc[dataset['user']==name, 'bloc'] =  user_data.loc[i,'blok']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-egyptian",
   "metadata": {},
   "source": [
    "add weeks and month years for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dynamic-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "monthly-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.loc[i,'datetime'].year == 2020:\n",
    "        dataset.loc[i,'week'] = int(dataset.loc[i,'datetime'].isocalendar()[1])\n",
    "    \n",
    "    \n",
    "    elif dataset.loc[i,'datetime'].year == 2021:\n",
    "        dataset.loc[i,'week'] = int(dataset.loc[i,'datetime'].isocalendar()[1] + 52)\n",
    "    else:\n",
    "         dataset.loc[i,'week'] = \"old don't use\"\n",
    "\n",
    "monthyears = [datetime.strptime(str(dataset.loc[i,'datetime'].month) + \"-\" + str(dataset.loc[i,'datetime'].year),\"%m-%Y\") for i in range(len(dataset))]\n",
    "dataset['monthyear'] = monthyears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-organic",
   "metadata": {},
   "source": [
    "Make top 10, superuser and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "respective-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = dataset.groupby([\"name\",\"bloc\"]).agg({\"name\": ['count']})['name']\n",
    "user_list = user_list.sort_values(by = \"count\", ascending=False)\n",
    "user_list.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sorted-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper bound: 206.75\n",
      "lower bound: -47.5\n"
     ]
    }
   ],
   "source": [
    "q3, q1 = np.percentile(user_list['count'], [75 ,25])\n",
    "iqr = q3 - q1\n",
    "upper = user_list['count'].mean() + 1.5 * iqr\n",
    "lower = user_list['count'].mean() - 1.5 * iqr\n",
    "user_list['count'].mean()\n",
    "print(\"upper bound:\", upper)\n",
    "print(\"lower bound:\", lower)\n",
    "superusers = user_list[user_list['count'] > upper]['name']\n",
    "dataset['superuser'] = [1 if dataset.loc[i,'name'] in list(superusers) else 0 for i in range(len(dataset))]\n",
    "ten_percent = user_list.head(13)['name']\n",
    "dataset['tenpercent'] = [1 if dataset.loc[i,'name'] in list(ten_percent) else 0 for i in range(len(dataset))]\n",
    "percentiles = list(np.percentile(user_list['count'], [0,10,20,30,40,50,60,70,80,90]))\n",
    "#percentile = 1\n",
    "for i in percentiles: \n",
    "    names = user_list[user_list['count'] >= i]['name']\n",
    "    dataset.loc[dataset['name'].isin(names),'percentile'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "common-identity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[dataset['user'] != \"nikolajvillumsen\"]\n",
    "dataset.loc[dataset['party'] == \"Frie Grønne\", 'party'] = \"Løsgænger\"\n",
    "#frie grønne er løsgænger fra: https://www.ft.dk/da/medlemmer/mandatfordelingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "tropical-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_one = [1 if dataset.loc[i,'n_women'] > 0 else 0 for i in range(len(dataset))]\n",
    "dataset['women_binary'] = women_one\n",
    "men_one = [1 if dataset.loc[i,'n_men'] > 0 else 0 for i in range(len(dataset))]\n",
    "dataset['men_binary'] = men_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41285e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['year_week'] = [str(dataset.date_clean[i].year) + \"_\" +  str(dataset.date_clean[i].week) for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b728f",
   "metadata": {},
   "source": [
    "Standardize the amount of women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "390a7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x,mean,std):\n",
    "    z = (x-mean) / std\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fd88766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnv664\\AppData\\Local\\Temp/ipykernel_14592/3642598273.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z = (x-mean) / std\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pol in dataset.user.unique():\n",
    "    dat = dataset.loc[dataset['user'] == pol,'n_women']\n",
    "\n",
    "    \n",
    "    my = np.mean(dat)\n",
    "    std = np.std(dat)\n",
    "    dataset.loc[dataset['user'] == pol,'std_n_women'] = [standardize(dat[i],my,std) for i in dat.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ae29603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset.std_n_women.isna(), 'std_n_women'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c873e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.days_till_linde  = dataset.days_till_linde * -1 #reverse\n",
    "dataset.days_till_linde  =  dataset['days_till_linde'].astype(int) \n",
    "\n",
    "dataset['week'] = np.floor((dataset.days_till_linde) /7) #1 is the first week with treatment\n",
    "dataset['fourteen_days'] = np.floor((dataset.days_till_linde) /14) #1 is the first week with treatment\n",
    "dataset['month'] = np.floor((dataset.days_till_linde) /30) #1 is the first week with treatment\n",
    "\n",
    "dataset['week'] = dataset['week'].astype(int)\n",
    "dataset['fourteen_days'] = dataset['fourteen_days'].astype(int)\n",
    "dataset['month'] = dataset['month'].astype(int)\n",
    "\n",
    "\n",
    "dataset['week_after'] = [dataset.loc[i,'week'] if dataset.loc[i,'week'] >= 0 else -1 for i in range(len(dataset))]\n",
    "dataset['fourteen_days_after'] = [dataset.loc[i,'fourteen_days'] if dataset.loc[i,'fourteen_days'] >= 0 else -1 for i in range(len(dataset))]\n",
    "dataset['month_after'] = [dataset.loc[i,'month'] if dataset.loc[i,'month'] >= 0 else -1 for i in range(len(dataset))]\n",
    "dataset['days_till_linde_after'] = [dataset.loc[i,'days_till_linde'] if dataset.loc[i,'days_till_linde'] >= 1 else -1 for i in range(len(dataset))]\n",
    "\n",
    "\n",
    "#assign all period before as \"control\"\n",
    "\n",
    "#recode the last week into the second to last, as there are only two obs in the last week\n",
    "dataset.loc[dataset['week'] == 25,'week'] = 24\n",
    "dataset.loc[dataset['week_after'] == 25,'week_after'] = 24\n",
    "\n",
    "dataset.loc[dataset['month'] == 6,'month'] = 5 # very few observations in the last month\n",
    "dataset.loc[dataset['month_after'] == 6,'month_after'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-collapse",
   "metadata": {},
   "source": [
    "I then save the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "indirect-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"data/cleandata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ac025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
