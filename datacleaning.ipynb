{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46d0c329",
   "metadata": {},
   "source": [
    "# This script takes the rawdataset.csv, users.txt, face_vars.csv and usernames.csv and cleans it in a myriad of ways. It outputs a cleandata.csv where it is all combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplt\n",
    "from IPython.display import display, clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-qualification",
   "metadata": {},
   "source": [
    "importing a list of the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "statutory-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data\\\\users.txt\",'r') as file:\n",
    "    users = file.read().splitlines() \n",
    "    #users = [post[:-1] for post in users]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-harbor",
   "metadata": {},
   "source": [
    "reading in all the csv files from the subfolders, and appending them to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "double-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(columns=['post_nr', 'date', 'text', 'likes', 'user', 'piclink', 'postlink'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adverse-korean",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    path =  \"posts\\\\\"+ user +\"\\\\\" \n",
    "    csv_path = path + user +\".csv\"\n",
    "    pic_path = path + user + \"_piclinks.txt\"\n",
    "    post_path = path + user + \"_postlinks.txt\"\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(csv_path, usecols = [1,2,3,4])\n",
    "    \n",
    "    #concat the username\n",
    "    df['user'] = user\n",
    "    \n",
    "    with open(pic_path, 'r') as file:\n",
    "        pic_links = file.read().splitlines()\n",
    "    with open(post_path, 'r') as file:\n",
    "        post_links = file.read().splitlines()\n",
    "    \n",
    "    df['piclink'] = pic_links\n",
    "    df['postlink'] = post_links\n",
    "    #append the dataset\n",
    "    dataset = dataset.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-candidate",
   "metadata": {},
   "source": [
    "Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "confidential-confidentiality",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "third-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"rawdataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accessible-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"rawdataset.csv\", usecols=[2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "colored-employer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_nr</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "      <td>Nunarput 鮫봺잺</td>\n",
       "      <td>71 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4 DAYS AGO</td>\n",
       "      <td>So proud of @kunofencker. 游끥游끥游끥 You won the nati...</td>\n",
       "      <td>71 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FEBRUARY 2</td>\n",
       "      <td>Many people ask me how I can work as a parliam...</td>\n",
       "      <td>100 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JANUARY 23</td>\n",
       "      <td>Relatable af</td>\n",
       "      <td>108 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DECEMBER 22, 2020</td>\n",
       "      <td>So excited for the kids to get home to us. I e...</td>\n",
       "      <td>19 likes</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>19</td>\n",
       "      <td>MARCH 19, 2019</td>\n",
       "      <td>P친 vej til Ilulissat 仇벒잺 Gl칝der mig. H친ber p친 g...</td>\n",
       "      <td>24 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11680</th>\n",
       "      <td>20</td>\n",
       "      <td>FEBRUARY 23, 2019</td>\n",
       "      <td>S친 er vi klar til at heppe p친 @nina_k_j og Jul...</td>\n",
       "      <td>47 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>21</td>\n",
       "      <td>FEBRUARY 14, 2019</td>\n",
       "      <td>Disse dage bes칮ger jeg Tasiilaq. Det er s친 smu...</td>\n",
       "      <td>41 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11682</th>\n",
       "      <td>22</td>\n",
       "      <td>DECEMBER 11, 2018</td>\n",
       "      <td>Veloverst친et samtale salon med @emileperonard ...</td>\n",
       "      <td>45 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>23</td>\n",
       "      <td>DECEMBER 9, 2018</td>\n",
       "      <td>Sapaassuit aappaanni pilluaritsi 游꾼游낗游땕游섫릖 Gl칝deli...</td>\n",
       "      <td>36 likes</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11684 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_nr               date  \\\n",
       "0            0         3 DAYS AGO   \n",
       "1            1         4 DAYS AGO   \n",
       "2            2         FEBRUARY 2   \n",
       "3            3         JANUARY 23   \n",
       "4            4  DECEMBER 22, 2020   \n",
       "...        ...                ...   \n",
       "11679       19     MARCH 19, 2019   \n",
       "11680       20  FEBRUARY 23, 2019   \n",
       "11681       21  FEBRUARY 14, 2019   \n",
       "11682       22  DECEMBER 11, 2018   \n",
       "11683       23   DECEMBER 9, 2018   \n",
       "\n",
       "                                                    text      likes  \\\n",
       "0                                            Nunarput 鮫봺잺   71 likes   \n",
       "1      So proud of @kunofencker. 游끥游끥游끥 You won the nati...   71 likes   \n",
       "2      Many people ask me how I can work as a parliam...  100 likes   \n",
       "3                                           Relatable af  108 likes   \n",
       "4      So excited for the kids to get home to us. I e...   19 likes   \n",
       "...                                                  ...        ...   \n",
       "11679  P친 vej til Ilulissat 仇벒잺 Gl칝der mig. H친ber p친 g...   24 likes   \n",
       "11680  S친 er vi klar til at heppe p친 @nina_k_j og Jul...   47 likes   \n",
       "11681  Disse dage bes칮ger jeg Tasiilaq. Det er s친 smu...   41 likes   \n",
       "11682  Veloverst친et samtale salon med @emileperonard ...   45 likes   \n",
       "11683  Sapaassuit aappaanni pilluaritsi 游꾼游낗游땕游섫릖 Gl칝deli...   36 likes   \n",
       "\n",
       "                user  \n",
       "0            akimati  \n",
       "1            akimati  \n",
       "2            akimati  \n",
       "3            akimati  \n",
       "4            akimati  \n",
       "...              ...  \n",
       "11679  aaja_chemnitz  \n",
       "11680  aaja_chemnitz  \n",
       "11681  aaja_chemnitz  \n",
       "11682  aaja_chemnitz  \n",
       "11683  aaja_chemnitz  \n",
       "\n",
       "[11684 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-groove",
   "metadata": {},
   "source": [
    "Clean up some of the data. I begin by making likes into an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "impaired-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "like_col = dataset['likes']\n",
    "likes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eligible-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in like_col:\n",
    "    if str(txt) != \"nan\":\n",
    "        num = str(txt).split()[0]\n",
    "        num = num.replace(\",\",\"\")\n",
    "        num = num.replace(\".\",\"\")\n",
    "        likes.append(int(num))\n",
    "    else:\n",
    "        likes.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "better-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['likes'] = likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "every-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_nr</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3 DAYS AGO</td>\n",
       "      <td>Nunarput 鮫봺잺</td>\n",
       "      <td>71.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4 DAYS AGO</td>\n",
       "      <td>So proud of @kunofencker. 游끥游끥游끥 You won the nati...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>FEBRUARY 2</td>\n",
       "      <td>Many people ask me how I can work as a parliam...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>JANUARY 23</td>\n",
       "      <td>Relatable af</td>\n",
       "      <td>108.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>DECEMBER 22, 2020</td>\n",
       "      <td>So excited for the kids to get home to us. I e...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>akimati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11679</th>\n",
       "      <td>19</td>\n",
       "      <td>MARCH 19, 2019</td>\n",
       "      <td>P친 vej til Ilulissat 仇벒잺 Gl칝der mig. H친ber p친 g...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11680</th>\n",
       "      <td>20</td>\n",
       "      <td>FEBRUARY 23, 2019</td>\n",
       "      <td>S친 er vi klar til at heppe p친 @nina_k_j og Jul...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11681</th>\n",
       "      <td>21</td>\n",
       "      <td>FEBRUARY 14, 2019</td>\n",
       "      <td>Disse dage bes칮ger jeg Tasiilaq. Det er s친 smu...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11682</th>\n",
       "      <td>22</td>\n",
       "      <td>DECEMBER 11, 2018</td>\n",
       "      <td>Veloverst친et samtale salon med @emileperonard ...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11683</th>\n",
       "      <td>23</td>\n",
       "      <td>DECEMBER 9, 2018</td>\n",
       "      <td>Sapaassuit aappaanni pilluaritsi 游꾼游낗游땕游섫릖 Gl칝deli...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>aaja_chemnitz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11684 rows 칑 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       post_nr               date  \\\n",
       "0            0         3 DAYS AGO   \n",
       "1            1         4 DAYS AGO   \n",
       "2            2         FEBRUARY 2   \n",
       "3            3         JANUARY 23   \n",
       "4            4  DECEMBER 22, 2020   \n",
       "...        ...                ...   \n",
       "11679       19     MARCH 19, 2019   \n",
       "11680       20  FEBRUARY 23, 2019   \n",
       "11681       21  FEBRUARY 14, 2019   \n",
       "11682       22  DECEMBER 11, 2018   \n",
       "11683       23   DECEMBER 9, 2018   \n",
       "\n",
       "                                                    text  likes           user  \n",
       "0                                            Nunarput 鮫봺잺   71.0        akimati  \n",
       "1      So proud of @kunofencker. 游끥游끥游끥 You won the nati...   71.0        akimati  \n",
       "2      Many people ask me how I can work as a parliam...  100.0        akimati  \n",
       "3                                           Relatable af  108.0        akimati  \n",
       "4      So excited for the kids to get home to us. I e...   19.0        akimati  \n",
       "...                                                  ...    ...            ...  \n",
       "11679  P친 vej til Ilulissat 仇벒잺 Gl칝der mig. H친ber p친 g...   24.0  aaja_chemnitz  \n",
       "11680  S친 er vi klar til at heppe p친 @nina_k_j og Jul...   47.0  aaja_chemnitz  \n",
       "11681  Disse dage bes칮ger jeg Tasiilaq. Det er s친 smu...   41.0  aaja_chemnitz  \n",
       "11682  Veloverst친et samtale salon med @emileperonard ...   45.0  aaja_chemnitz  \n",
       "11683  Sapaassuit aappaanni pilluaritsi 游꾼游낗游땕游섫릖 Gl칝deli...   36.0  aaja_chemnitz  \n",
       "\n",
       "[11684 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-saturday",
   "metadata": {},
   "source": [
    "I then change the date\n",
    "- at the very first i change the once with \"4 days ago \" etc into they apporpriate dates\n",
    "- then i split the standard date formatsinto day, month year - 3 different cols \n",
    "- i then make a combined date col\n",
    "- i then make this col into a datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aware-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = dataset['date']\n",
    "dates = []\n",
    "day = []\n",
    "month = []\n",
    "year = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(i):\n",
    "    if i == \"JANUARY\" or i == \"JANUAR\":\n",
    "        return 1\n",
    "    elif i == \"FEBRUARY\" or i == \"FEBRUAR\":\n",
    "        return 2\n",
    "    elif i == \"MARCH\" or i == \"MARTS\":\n",
    "        return 3\n",
    "    elif i == \"APRIL\":\n",
    "        return 4\n",
    "    elif i == \"MAY\"or i == \"MAJ\":\n",
    "        return 5\n",
    "    elif i == \"JUNE\"or i == \"JUNI\":\n",
    "        return 6\n",
    "    elif i == \"JULY\"or i == \"JULI\":\n",
    "        return 7\n",
    "    elif i == \"AUGUST\":\n",
    "        return 8\n",
    "    elif i == \"SEPTEMBER\":\n",
    "        return 9\n",
    "    elif i == \"OCTOBER\"or i == \"OKTOBER\":\n",
    "        return 10\n",
    "    elif i == \"NOVEMBER\":\n",
    "        return 11\n",
    "    elif i == \"DECEMBER\":\n",
    "        return 12\n",
    "    return i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "casual-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_month = [\"JANUARY\",\n",
    "                 \"JANUAR\",\n",
    "                 \"FEBRUARY\",\n",
    "                 \"FEBRUAR\",\n",
    "                 \"MARCH\",\n",
    "                 \"MARTS\",\n",
    "                 \"APRIL\",\n",
    "                 \"MAY\",\n",
    "                 \"MAJ\",\n",
    "                 \"JUNE\",\n",
    "                 \"JUNI\",\n",
    "                 \"JULY\",\n",
    "                 \"JULI\",\n",
    "                 \"AUGUST\",\n",
    "                 \"SEPTEMBER\",\n",
    "                 \"OCTOBER\",\n",
    "                 \"OKTOBER\",\n",
    "                 \"NOVEMBER\",\n",
    "                 \"DECEMBER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "binding-village",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dt in date_col:\n",
    "    #if it is not nan\n",
    "    if str(dt) != \"nan\":\n",
    "        #this works for all the normal dates, also the ones with out year. but not for the \"x days ago\"\n",
    "        split_date = dt.split(maxsplit = 3)\n",
    "        #print(split_date)\n",
    "        \n",
    "        #if the month is first (format -m-d-y)\n",
    "        if split_date[0] in list_of_month:\n",
    "            month.append(mapping(split_date[0]))\n",
    "            day.append(split_date[1].replace(\",\",\"\"))\n",
    "            try:\n",
    "                year.append(split_date[2])\n",
    "            except:\n",
    "                #if there is no year, it means that it is the current year\n",
    "                year.append(2021)\n",
    "            #append in y-m-d format\n",
    "            dates.append(str(year[-1]) + \"-\" + str(month[-1]) + \"-\" + str(day[-1]))\n",
    "        #If the format is d-m-y\n",
    "        elif split_date[1] in list_of_month:\n",
    "            month.append(mapping(split_date[1]))\n",
    "            day.append(split_date[0].replace(\".\",\"\"))\n",
    "            try:\n",
    "                year.append(split_date[2])\n",
    "            except:\n",
    "                #if there is no year, it means that it is the current year\n",
    "                year.append(2021)\n",
    "                \n",
    "            #append in y-m-d format\n",
    "            dates.append(str(year[-1]) + \"-\" + str(month[-1]) + \"-\" + str(day[-1]))\n",
    "        else:\n",
    "            #there are 2 formats Danish and English for \"3 days ago\" or \"For 3 dage siden\"\n",
    "            #they are all subtracted from the 18-02-2021. This is not entirely correct \n",
    "            # as some post were scraped on the 15th, 16th and 17th. However the notes on which are lost on a broken harddisk\n",
    "            # it does not matter for the results. as i examine the periode clode to 26th Feb 2020. \n",
    "            if dt.split()[0].isdigit():\n",
    "                day.append(18 - int(dt.split()[0]))\n",
    "            elif dt.split()[1].isdigit():\n",
    "                day.append(18 - int(dt.split()[1]))\n",
    "            #all in February 2021\n",
    "            month.append(2)\n",
    "            year.append(2021)\n",
    "            \n",
    "            dates.append(str(year[-1]) + \"-\" + str(month[-1]) + \"-\" + str(day[-1]))\n",
    "\n",
    "\n",
    "    else:\n",
    "        day.append(np.nan)\n",
    "        month.append(np.nan)\n",
    "        year.append(np.nan)\n",
    "        dates.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "breeding-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['date_clean'] = dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-upgrade",
   "metadata": {},
   "source": [
    "I then make the date into a datetime object and calculate the days till the 26th of August 2020, the date of the speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handmade-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "linde_date = datetime.strptime(\"2020-08-26\", \"%Y-%m-%d\")\n",
    "linde_date_06 = datetime.strptime(\"2020-09-06\", \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "subtle-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetimes = []\n",
    "datedif = []\n",
    "datedif_06 = []\n",
    "for dt in dataset['date_clean']:\n",
    "    try:\n",
    "        datetimes.append(datetime.strptime(dt, \"%Y-%m-%d\"))\n",
    "        datedif.append((datetimes[-1] - linde_date).days)\n",
    "        datedif_06.append((datetimes[-1] - linde_date_06).days)\n",
    "\n",
    "    except: \n",
    "        try:\n",
    "            datetimes.append(datetime.strptime(dt, \"%Y-%m-%d\"))\n",
    "            datedif.append((datetimes[-1] - linde_date).days)\n",
    "            datedif_06.append((datetimes[-1] - linde_date_06).days)\n",
    "\n",
    "        except:\n",
    "            datetimes.append(np.nan)\n",
    "            datedif.append(np.nan)\n",
    "            datedif_06.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "weird-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['datetime'] = datetimes\n",
    "dataset['days_till_linde'] = datedif\n",
    "dataset['days_till_linde_06'] = datedif_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "million-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir(\"C:\\\\Users\\\\August\\\\OneDrive - K칮benhavns Universitet\\\\Documents\\\\Uni\\\\Kandidat i Statskundskab\\\\Speciale\\\\kode\")\n",
    "#dataset = pd.read_csv(\"cleandata.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mediterranean-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"C:\\\\Users\\\\August\\\\OneDrive - K칮benhavns Universitet\\\\Documents\\\\Uni\\\\Kandidat i Statskundskab\\\\Speciale\\\\kode\\\\posts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "outstanding-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset[\"path\"] = [path + \"\\\\\" + str(dataset['user'][i]) + \"\\\\pic_\" + str(dataset['post_nr'][i]) + \".jpeg\" for i in range(len(dataset))]\n",
    "dataset[\"path\"] = [\"posts\\\\\" + str(dataset['user'][i]) + \"\\\\pic_\" + str(dataset['post_nr'][i]) + \".jpeg\" for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-quarterly",
   "metadata": {},
   "source": [
    "## read in the gender amount of people data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "thirty-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dataset = pd.read_csv(\"data\\\\face_vars.csv\",index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "broke-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['n_people'] = gender_dataset['n_people']\n",
    "dataset['n_women'] = gender_dataset['n_women']\n",
    "dataset['n_men'] = gender_dataset['n_men']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d843a",
   "metadata": {},
   "source": [
    "Remove imagewith more than 4 people (5 or more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5799d79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove observations from before the alloted time)\n",
    "dateend = datetime(2021,2,4)\n",
    "dstart = datetime(2020,2,26)\n",
    "linde_date = datetime.strptime(\"2020-08-26\", \"%Y-%m-%d\")\n",
    "dataset = dataset[dataset['datetime'] > dstart]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11810b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnv664\\AppData\\Local\\Temp/ipykernel_14592/2280790094.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['date_clean'] = [datetime.strptime(str(d), \"%Y-%m-%d\") for d in dataset['date_clean']]\n"
     ]
    }
   ],
   "source": [
    "dataset['date_clean'] = [datetime.strptime(str(d), \"%Y-%m-%d\") for d in dataset['date_clean']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d10f4471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10416"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d13b1d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "47.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(dataset['n_people'] > 4))\n",
    "print(dataset['n_people'].max())\n",
    "dataset = dataset[dataset['n_people'] < 5]\n",
    "dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93977d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10192"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c76d9c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-peripheral",
   "metadata": {},
   "source": [
    "I make a share of women var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "exclusive-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    \n",
    "    try:\n",
    "        dataset.loc[i,'share_women'] = int(dataset.loc[i,'n_women']) / int(dataset.loc[i,'n_people'])\n",
    "        dataset.loc[i,'share_women_no_none'] = int(dataset.loc[i,'n_women']) / int(dataset.loc[i,'n_people'])\n",
    "    except ZeroDivisionError:\n",
    "        dataset.loc[i,'share_women'] = 0\n",
    "        dataset.loc[i,'share_women_no_none'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-memorabilia",
   "metadata": {},
   "source": [
    "I then define if it is before or after linde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "golden-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "before =dataset['datetime'] < linde_date\n",
    "after = dataset['datetime'] >= linde_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "important-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#published on the 11th of september\n",
    "before_06 =dataset['datetime'] < linde_date + timedelta(11)\n",
    "after_06 = dataset['datetime'] >= linde_date + timedelta(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nervous-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[before,'treatment'] = 0\n",
    "dataset.loc[after,'treatment'] = 1\n",
    "dataset.loc[before_06,'treatment_06'] = 0\n",
    "dataset.loc[after_06,'treatment_06'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-contrary",
   "metadata": {},
   "source": [
    "I proceed to remove the observations without a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "treated-transsexual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                   0\n",
       "index                     0\n",
       "post_nr                   0\n",
       "date                      0\n",
       "text                    164\n",
       "likes                   966\n",
       "user                      0\n",
       "date_clean                0\n",
       "datetime                  0\n",
       "days_till_linde           0\n",
       "days_till_linde_06        0\n",
       "path                      0\n",
       "n_people                  0\n",
       "n_women                   0\n",
       "n_men                     0\n",
       "share_women               0\n",
       "share_women_no_none    3941\n",
       "treatment                 0\n",
       "treatment_06              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "raised-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['date'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "balanced-shape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level_0                   0\n",
       "index                     0\n",
       "post_nr                   0\n",
       "date                      0\n",
       "text                    164\n",
       "likes                   966\n",
       "user                      0\n",
       "date_clean                0\n",
       "datetime                  0\n",
       "days_till_linde           0\n",
       "days_till_linde_06        0\n",
       "path                      0\n",
       "n_people                  0\n",
       "n_women                   0\n",
       "n_men                     0\n",
       "share_women               0\n",
       "share_women_no_none    3941\n",
       "treatment                 0\n",
       "treatment_06              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "joint-watch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10192"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "theoretical-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_data = pd.read_csv(\"data\\\\usernames.csv\", sep=\";\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "healthy-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>navn</th>\n",
       "      <th>k칮n</th>\n",
       "      <th>parti</th>\n",
       "      <th>blok</th>\n",
       "      <th>dato for indsamling</th>\n",
       "      <th>valgperiode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akimati</td>\n",
       "      <td>Aki-Matilda H칮egh-Dam</td>\n",
       "      <td>f</td>\n",
       "      <td>Siumut</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alexvanopslagh</td>\n",
       "      <td>Alex Vanopslagh</td>\n",
       "      <td>m</td>\n",
       "      <td>Liberal Alliance</td>\n",
       "      <td>b</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>andreas.steenberg</td>\n",
       "      <td>Andreas Steenberg</td>\n",
       "      <td>m</td>\n",
       "      <td>Radikale venstre</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anehalsboe</td>\n",
       "      <td>Ane Halsboe-J칮rgensen</td>\n",
       "      <td>f</td>\n",
       "      <td>Socialdemokratiet</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>annehonoreoestergaard</td>\n",
       "      <td>Anne Honor칠 칒stergaard</td>\n",
       "      <td>f</td>\n",
       "      <td>Venstre</td>\n",
       "      <td>b</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>troelsravn1</td>\n",
       "      <td>Troels Ravn</td>\n",
       "      <td>m</td>\n",
       "      <td>Socialdemokratiet</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ullatornaes</td>\n",
       "      <td>Ulla T칮rn칝s</td>\n",
       "      <td>f</td>\n",
       "      <td>Venstre</td>\n",
       "      <td>b</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>victoria.r.velasquez</td>\n",
       "      <td>Victoria Vela?squez</td>\n",
       "      <td>f</td>\n",
       "      <td>Enhedslisten</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>zenia.stampe</td>\n",
       "      <td>Zenia Stampe</td>\n",
       "      <td>f</td>\n",
       "      <td>Radikale venstre</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>aaja_chemnitz</td>\n",
       "      <td>aaja chemnitz larsen</td>\n",
       "      <td>f</td>\n",
       "      <td>Inuit Ataqatigiit</td>\n",
       "      <td>r</td>\n",
       "      <td>11-03-2021</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows 칑 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user                    navn k칮n               parti  \\\n",
       "0                  akimati   Aki-Matilda H칮egh-Dam    f             Siumut   \n",
       "1           alexvanopslagh         Alex Vanopslagh    m   Liberal Alliance   \n",
       "2        andreas.steenberg       Andreas Steenberg    m   Radikale venstre   \n",
       "3               anehalsboe   Ane Halsboe-J칮rgensen    f  Socialdemokratiet   \n",
       "4    annehonoreoestergaard  Anne Honor칠 칒stergaard    f            Venstre   \n",
       "..                     ...                     ...  ...                ...   \n",
       "131            troelsravn1             Troels Ravn    m  Socialdemokratiet   \n",
       "132            ullatornaes             Ulla T칮rn칝s    f            Venstre   \n",
       "133   victoria.r.velasquez     Victoria Vela?squez    f       Enhedslisten   \n",
       "134           zenia.stampe            Zenia Stampe    f   Radikale venstre   \n",
       "135          aaja_chemnitz    aaja chemnitz larsen    f  Inuit Ataqatigiit   \n",
       "\n",
       "    blok dato for indsamling  valgperiode  \n",
       "0      r          11-03-2021         2019  \n",
       "1      b          11-03-2021         2019  \n",
       "2      r          11-03-2021         2019  \n",
       "3      r          11-03-2021         2019  \n",
       "4      b          11-03-2021         2019  \n",
       "..   ...                 ...          ...  \n",
       "131    r          11-03-2021         2019  \n",
       "132    b          11-03-2021         2019  \n",
       "133    r          11-03-2021         2019  \n",
       "134    r          11-03-2021         2019  \n",
       "135    r          11-03-2021         2019  \n",
       "\n",
       "[136 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "accomplished-catalyst",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(user_data)):\n",
    "    name = user_data.loc[i,'user']\n",
    "    \n",
    "    dataset.loc[dataset['user']==name,'name'] =  user_data.loc[i,'navn']\n",
    "    dataset.loc[dataset['user']==name,'sex'] =  user_data.loc[i,'k칮n ']\n",
    "    dataset.loc[dataset['user']==name, 'party'] =  user_data.loc[i,'parti']\n",
    "    dataset.loc[dataset['user']==name, 'bloc'] =  user_data.loc[i,'blok']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-egyptian",
   "metadata": {},
   "source": [
    "add weeks and month years for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dynamic-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "monthly-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    if dataset.loc[i,'datetime'].year == 2020:\n",
    "        dataset.loc[i,'week'] = int(dataset.loc[i,'datetime'].isocalendar()[1])\n",
    "    \n",
    "    \n",
    "    elif dataset.loc[i,'datetime'].year == 2021:\n",
    "        dataset.loc[i,'week'] = int(dataset.loc[i,'datetime'].isocalendar()[1] + 52)\n",
    "    else:\n",
    "         dataset.loc[i,'week'] = \"old don't use\"\n",
    "\n",
    "monthyears = [datetime.strptime(str(dataset.loc[i,'datetime'].month) + \"-\" + str(dataset.loc[i,'datetime'].year),\"%m-%Y\") for i in range(len(dataset))]\n",
    "dataset['monthyear'] = monthyears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-organic",
   "metadata": {},
   "source": [
    "Make top 10, superuser and percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "respective-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = dataset.groupby([\"name\",\"bloc\"]).agg({\"name\": ['count']})['name']\n",
    "user_list = user_list.sort_values(by = \"count\", ascending=False)\n",
    "user_list.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sorted-element",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upper bound: 206.75\n",
      "lower bound: -47.5\n"
     ]
    }
   ],
   "source": [
    "q3, q1 = np.percentile(user_list['count'], [75 ,25])\n",
    "iqr = q3 - q1\n",
    "upper = user_list['count'].mean() + 1.5 * iqr\n",
    "lower = user_list['count'].mean() - 1.5 * iqr\n",
    "user_list['count'].mean()\n",
    "print(\"upper bound:\", upper)\n",
    "print(\"lower bound:\", lower)\n",
    "superusers = user_list[user_list['count'] > upper]['name']\n",
    "dataset['superuser'] = [1 if dataset.loc[i,'name'] in list(superusers) else 0 for i in range(len(dataset))]\n",
    "ten_percent = user_list.head(13)['name']\n",
    "dataset['tenpercent'] = [1 if dataset.loc[i,'name'] in list(ten_percent) else 0 for i in range(len(dataset))]\n",
    "percentiles = list(np.percentile(user_list['count'], [0,10,20,30,40,50,60,70,80,90]))\n",
    "#percentile = 1\n",
    "for i in percentiles: \n",
    "    names = user_list[user_list['count'] >= i]['name']\n",
    "    dataset.loc[dataset['name'].isin(names),'percentile'] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "common-identity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset[dataset['user'] != \"nikolajvillumsen\"]\n",
    "dataset.loc[dataset['party'] == \"Frie Gr칮nne\", 'party'] = \"L칮sg칝nger\"\n",
    "#frie gr칮nne er l칮sg칝nger fra: https://www.ft.dk/da/medlemmer/mandatfordelingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "tropical-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "women_one = [1 if dataset.loc[i,'n_women'] > 0 else 0 for i in range(len(dataset))]\n",
    "dataset['women_binary'] = women_one\n",
    "men_one = [1 if dataset.loc[i,'n_men'] > 0 else 0 for i in range(len(dataset))]\n",
    "dataset['men_binary'] = men_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41285e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['year_week'] = [str(dataset.date_clean[i].year) + \"_\" +  str(dataset.date_clean[i].week) for i in range(len(dataset))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b728f",
   "metadata": {},
   "source": [
    "Standardize the amount of women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "390a7e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x,mean,std):\n",
    "    z = (x-mean) / std\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fd88766",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnv664\\AppData\\Local\\Temp/ipykernel_14592/3642598273.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  z = (x-mean) / std\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pol in dataset.user.unique():\n",
    "    dat = dataset.loc[dataset['user'] == pol,'n_women']\n",
    "\n",
    "    \n",
    "    my = np.mean(dat)\n",
    "    std = np.std(dat)\n",
    "    dataset.loc[dataset['user'] == pol,'std_n_women'] = [standardize(dat[i],my,std) for i in dat.index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ae29603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.loc[dataset.std_n_women.isna(), 'std_n_women'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c873e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.days_till_linde  = dataset.days_till_linde * -1 #reverse\n",
    "dataset.days_till_linde  =  dataset['days_till_linde'].astype(int) \n",
    "\n",
    "dataset['week'] = np.floor((dataset.days_till_linde) /7) #1 is the first week with treatment\n",
    "dataset['fourteen_days'] = np.floor((dataset.days_till_linde) /14) #1 is the first week with treatment\n",
    "dataset['month'] = np.floor((dataset.days_till_linde) /30) #1 is the first week with treatment\n",
    "\n",
    "dataset['week'] = dataset['week'].astype(int)\n",
    "dataset['fourteen_days'] = dataset['fourteen_days'].astype(int)\n",
    "dataset['month'] = dataset['month'].astype(int)\n",
    "\n",
    "\n",
    "dataset['week_after'] = [dataset.loc[i,'week'] if dataset.loc[i,'week'] >= 0 else -1 for i in range(len(dataset))]\n",
    "dataset['fourteen_days_after'] = [dataset.loc[i,'fourteen_days'] if dataset.loc[i,'fourteen_days'] >= 0 else -1 for i in range(len(dataset))]\n",
    "dataset['month_after'] = [dataset.loc[i,'month'] if dataset.loc[i,'month'] >= 0 else -1 for i in range(len(dataset))]\n",
    "dataset['days_till_linde_after'] = [dataset.loc[i,'days_till_linde'] if dataset.loc[i,'days_till_linde'] >= 1 else -1 for i in range(len(dataset))]\n",
    "\n",
    "\n",
    "#assign all period before as \"control\"\n",
    "\n",
    "#recode the last week into the second to last, as there are only two obs in the last week\n",
    "dataset.loc[dataset['week'] == 25,'week'] = 24\n",
    "dataset.loc[dataset['week_after'] == 25,'week_after'] = 24\n",
    "\n",
    "dataset.loc[dataset['month'] == 6,'month'] = 5 # very few observations in the last month\n",
    "dataset.loc[dataset['month_after'] == 6,'month_after'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-collapse",
   "metadata": {},
   "source": [
    "I then save the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "indirect-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"data/cleandata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ac025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
