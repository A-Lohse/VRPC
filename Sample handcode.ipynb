{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1794ec3f",
   "metadata": {},
   "source": [
    "# This script samples images and faces for handcoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe65b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from facelib import FaceDetector, AgeGenderEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea610c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import os\n",
    "import random\n",
    "\n",
    "# importing pandas as pd  \n",
    "import pandas as pd  \n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714f015",
   "metadata": {},
   "source": [
    "# For this scrip to run, you will need to request acess to the raw data images. you then need to place the posts folder in your working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b55482",
   "metadata": {},
   "source": [
    "# I make an input loop to create the hand coded labels. \n",
    "It takes 1000 random images, and outputs 1 random face from that image - this image i then code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6daa8b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610a7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"posts\"\n",
    "\n",
    "paths_list = []\n",
    "\n",
    "\n",
    "i = 0\n",
    "while i < 1000:\n",
    "    #draw random politician\n",
    "    int_1 = random.randint(0,len(os.listdir(path))-1)\n",
    "    \n",
    "    #create a path into the folder\n",
    "    impath = path + \"\\\\\"+ os.listdir(path)[int_1]+\"\\\\\" \n",
    "    \n",
    "    #draw a random image in that folder (the first 4 items are meta data)\n",
    "    int_2 = random.randint(4,len(os.listdir(impath))-1)\n",
    "    \n",
    "    #create path to selected image\n",
    "    impath = impath + os.listdir(impath)[int_2]\n",
    "    \n",
    "    #if we by some change have gotten something other than an image\n",
    "    if impath[-4:] != \"jpeg\":\n",
    "        continue\n",
    "    \n",
    "    #if the image is not already in the drawn images - save the im path\n",
    "    if impath not in paths_list:\n",
    "        paths_list.append(impath)\n",
    "        i +=1\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c1330b",
   "metadata": {},
   "source": [
    "Predict the amount of people in the images, and save the images with faces and boxes around for manual labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a537c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {'Female' : 'Woman',\n",
    "               'Male'   : 'Man'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01913629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from FaceDetector: weights loaded\n",
      "from AgeGenderEstimator: weights loaded\n"
     ]
    }
   ],
   "source": [
    "face_detector = FaceDetector(confidence_threshold=0.7)\n",
    "age_gender_detector = AgeGenderEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1272ede",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [08:32<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "face_list = []\n",
    "gender_list = []\n",
    "boxes_list = []\n",
    "    #try:\n",
    "    #    image = mplt.imread(impath)\n",
    "    #except:\n",
    "    #    continue\n",
    "ind = 0    \n",
    "n_people_list = []\n",
    "\n",
    "for p in tqdm(paths_list):\n",
    "    \n",
    "    #detect faces\n",
    "    image = mplt.imread(p)\n",
    "    image = np.array(image)\n",
    "\n",
    "    faces, boxes, scores, landmarks = face_detector.detect_align(image)\n",
    "    if len(faces) == 0:\n",
    "        n_people_list.append(0)\n",
    "        face_list.append([faces])\n",
    "        gender_list.append([faces]) #just empty tensor\n",
    "        boxes_list.append([boxes])\n",
    "        \n",
    "        img_pil = Image.fromarray(np.array(image))\n",
    "        img = ImageDraw.Draw(img_pil) \n",
    "        \n",
    "        img_pil.save(\"handcode\\\\all_people\\\\\" + str(ind) + \".jpeg\")\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        n_people_list.append(len(faces))\n",
    "        genders, ages = age_gender_detector.detect(faces)\n",
    "\n",
    "\n",
    "        img_pil = Image.fromarray(np.array(image))\n",
    "        img = ImageDraw.Draw(img_pil) \n",
    "        \n",
    "        #append faces - should not be done for manual labelling to avoid bias\n",
    "        #for i, f in enumerate(faces):\n",
    "         #   img.rectangle(np.array(boxes)[i],outline= \"red\")\n",
    "          #  img.text(xy = (np.array(boxes)[i][0],np.array(boxes)[i][1] + 15),\n",
    "           #          text = gender_dict[genders[i]],\n",
    "            #        fill = \"white\")\n",
    "\n",
    "        face_list.append([faces])\n",
    "        gender_list.append([genders])\n",
    "        boxes_list.append([boxes])\n",
    "        img_pil.save(\"handcode\\\\all_people\\\\\" + str(ind) + \".jpeg\")\n",
    "        #display(img_pil)\n",
    "    ind += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965b14c",
   "metadata": {},
   "source": [
    "I then sample 1000 faces from the found faces and label them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cc64a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1207"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_people = 0\n",
    "\n",
    "for f in face_list:\n",
    "    n_people += len(f[0])\n",
    "n_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48c08e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_to_keep = random.sample(range(n_people), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18258b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 out of 1000 images\r"
     ]
    }
   ],
   "source": [
    "number = 0\n",
    "keep = 0\n",
    "auto_gender = []\n",
    "img_name_face = []\n",
    "face_for_df = []\n",
    "\n",
    "\n",
    "for i, faces in enumerate(boxes_list):\n",
    "    if len(faces[0]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        for f, face in enumerate(faces[0]):\n",
    "            \n",
    "            if keep in faces_to_keep: #if one of the 1000 sampled faces\n",
    "                \n",
    "                \n",
    "                image = mplt.imread(\"handcode\\\\all_people\\\\\" + str(i) + \".jpeg\")\n",
    "                image = np.array(image)\n",
    "                img_pil = Image.fromarray(np.array(image))\n",
    "                img = ImageDraw.Draw(img_pil) \n",
    "\n",
    "                #draw the face on the images\n",
    "                img.rectangle(np.array(face),outline= \"red\", width=3) #draw the face\n",
    "                \n",
    "                face_for_df.append(face)\n",
    "\n",
    "                auto_gender.append(gender_dict[gender_list[i][0][f]]) #save the gender\n",
    "                img_name_face.append(paths_list[i])\n",
    "\n",
    "                str(i)+ \"_\" + str(f)\n",
    "                #img_pil.save(\"handcode\\\\random_face\\\\\" + str(i)+ \"_\" + str(f) + \".jpeg\") #save the image with 1 rectange\n",
    "                img_pil.save(\"handcode\\\\random_face\\\\\" + str(number) + \".jpeg\") #save the image with 1 rectange\n",
    "                keep += 1\n",
    "                number += 1\n",
    "            else:\n",
    "                keep +=1\n",
    "                continue\n",
    "            \n",
    "    print(str(i +1) + \" out of 1000 images\", end=\"\\r\")\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f201025",
   "metadata": {},
   "outputs": [],
   "source": [
    "handcode_dict_npeople = {'random_image_number': list(range(1000)) ,\n",
    "                        'image_name' : paths_list,\n",
    "                         'auto_people' : n_people_list\n",
    "                         }\n",
    "\n",
    "handcode_dict_gender = {'random_face_number' : list(range(1000)),\n",
    "                        'image_name' :  img_name_face,\n",
    "                        'face_tensor' : face_for_df,\n",
    "                         'auto_gender' :  auto_gender}\n",
    "\n",
    "                 \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca964937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(handcode_dict_npeople) \n",
    "df2 = pd.DataFrame(handcode_dict_gender) \n",
    "\n",
    "df1.to_csv('handcode\\\\n_people_autocode.csv') \n",
    "df2.to_csv('handcode\\\\gender_autocode.csv') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
